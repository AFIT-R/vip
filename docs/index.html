<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Variable Importance Plots • vip</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script><!-- sticky kit --><script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script><!-- pkgdown --><link href="pkgdown.css" rel="stylesheet">
<script src="pkgdown.js"></script><meta property="og:title" content="Variable Importance Plots">
<meta property="og:description" content="A general framework for constructing variable importance plots from 
  various types machine learning models in R. Aside from some standard model-
  based variable importance measures, this package also provides a novel 
  approach based on partial dependence plots (PDPs) and individual conditional 
  expectation (ICE) curves as described in Greenwell et al. (2018) 
  &lt;arXiv:1805.04755&gt;.">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="index.html">vip</a>
        <span class="label label-default" data-toggle="tooltip" data-placement="bottom" title="Released package">0.1.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="reference/index.html">Reference</a>
</li>
<li>
  <a href="news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/koalaverse/vip">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9 contents">
    

    
    
<div id="vip-variable-importance-plots" class="section level1">
<div class="page-header"><h1 class="hasAnchor">
<a href="#vip-variable-importance-plots" class="anchor"></a>vip: Variable Importance Plots <img src="reference/figures/logo-vip.png" align="right" width="130" height="150">
</h1></div>

<div id="overview" class="section level2">
<h2 class="hasAnchor">
<a href="#overview" class="anchor"></a>Overview</h2>
<p>In the era of “big data”, it is becoming more of a challenge to not only build state-of-the-art predictive models, but also gain an understanding of what’s really going on in the data. For example, it is often of interest to know which, if any, of the predictors in a fitted model are relatively influential on the predicted outcome. Some modern algorithms—like random forests and gradient boosted decision trees—have a natural way of quantifying the importance or relative influence of each feature. Other algorithms—like naive Bayes classifiers and support vector machines—are not capable of doing so and model-free approaches are generally used to measure each predictor’s importance.</p>
<p>Enter <code>vip</code>, an R package for constructing variable importance (VI) scores/plots for many types of supervised learning algorithms using one of the following approaches:</p>
<ol style="list-style-type: decimal">
<li><p>Model-based VI scores (when available). For example, in a random forest, variable importance can be computed using the permutation approach described in <a href="https://doi.org/10.1023/A:1010933404324">Breiman (2001)</a>. Other supervised learning algorithms (like MARS and GBMs) have their own ways of constructing VI scores.</p></li>
<li><p>PDP-based VI scores. This is a new idea described in <a href="https://arxiv.org/abs/1805.04755">Greenwell et al. (2018)</a>. The idea is to measure the “flatness” of <a href="https://doi.org/10.1214/aos/1013203451">Friedman’s <em>partial dependence plot</em></a> (PDP) for each feature. A feature whose PDP is flat, relative to the other features, implies that the feature has less of an influence on the estimated prediction surface as it changes while taking into account the average effect of the other features in the model.</p></li>
<li><p>ICE-based VI scores. This method is similar to the PDP-based VI scores above, but are based on measuring the “flatness” of the <em>individual conditional expectation</em> (ICE) curves presented by <a href="https://doi.org/10.1080/10618600.2014.907095">Goldstein et al. (2014)</a>.</p></li>
</ol>
<p>Since PDPs and ICE curves can be constructed for any supervised learning algorithm, this means we can use methods 2) and 3) to construct VI scores for any supervised learning algorithm while taking into account the model and all of the features.</p>
</div>
<div id="installation" class="section level2">
<h2 class="hasAnchor">
<a href="#installation" class="anchor"></a>Installation</h2>
<p>The <code>vip</code> package is currently only available from GitHub, but can easily be installed using the <a href="https://CRAN.R-project.org/package=devtools">devtools</a> package:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="cf">if</span> (<span class="op">!</span><span class="kw">requireNamespace</span>(<span class="st">"devtools"</span>)) {</a>
<a class="sourceLine" id="cb1-2" data-line-number="2">  <span class="kw">install.packages</span>(<span class="st">"devtools"</span>)</a>
<a class="sourceLine" id="cb1-3" data-line-number="3">}</a>
<a class="sourceLine" id="cb1-4" data-line-number="4">devtools<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/devtools/topics/install_github">install_github</a></span>(<span class="st">"koalaverse/vip"</span>)</a></code></pre></div>
</div>
<div id="example-usage" class="section level2">
<h2 class="hasAnchor">
<a href="#example-usage" class="anchor"></a>Example usage</h2>
<p>For illustration, we use one of the regression problems described in Friedman (1991) and Breiman (1996). These data are available in the <a href="https://CRAN.R-project.org/package=mlbench">mlbench</a> package. The inputs consist of 10 independent variables uniformly distributed on the interval <span class="math inline">\(\left[0, 1\right]\)</span>; however, only 5 out of these 10 are actually used in the true model. Outputs are created according to the formula described in <code><a href="http://www.rdocumentation.org/packages/mlbench/topics/mlbench.friedman1">?mlbench::mlbench.friedman1</a></code>. The code chunk below simulates 500 observations from the model default standard deviation.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1"><span class="co"># Simulate training data</span></a>
<a class="sourceLine" id="cb2-2" data-line-number="2"><span class="kw">set.seed</span>(<span class="dv">101</span>)  <span class="co"># for reproducibility</span></a>
<a class="sourceLine" id="cb2-3" data-line-number="3">trn &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(mlbench<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/mlbench/topics/mlbench.friedman1">mlbench.friedman1</a></span>(<span class="dv">500</span>))  <span class="co"># ?mlbench.friedman1</span></a></code></pre></div>
<p>Next, we fit a random forest to the simulated data and construct variable importance plots using the two methods provided by the random forest algorithm (left and middle plots) and the (<strong>experimental</strong>) partial dependence-based approach (right plot). In this case, all three methods do a fantastic job at highlighting the five variables used in the true model.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="co"># Load required packages</span></a>
<a class="sourceLine" id="cb3-2" data-line-number="2"><span class="kw">library</span>(ggplot2)  <span class="co"># for ggtitle() </span></a>
<a class="sourceLine" id="cb3-3" data-line-number="3"><span class="kw">library</span>(randomForest)  </a>
<a class="sourceLine" id="cb3-4" data-line-number="4"><span class="kw">library</span>(vip)</a>
<a class="sourceLine" id="cb3-5" data-line-number="5"></a>
<a class="sourceLine" id="cb3-6" data-line-number="6"><span class="co"># Fit a random forest</span></a>
<a class="sourceLine" id="cb3-7" data-line-number="7"><span class="kw">set.seed</span>(<span class="dv">102</span>)</a>
<a class="sourceLine" id="cb3-8" data-line-number="8">rf &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/randomForest/topics/randomForest">randomForest</a></span>(y <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> trn, <span class="dt">importance =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb3-9" data-line-number="9"></a>
<a class="sourceLine" id="cb3-10" data-line-number="10"><span class="co"># Use `vi()` to return a tibble of variable importance scores</span></a>
<a class="sourceLine" id="cb3-11" data-line-number="11"><span class="kw"><a href="reference/vi.html">vi</a></span>(rf, <span class="dt">type =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb3-12" data-line-number="12"><span class="co">#&gt; # A tibble: 10 x 2</span></a>
<a class="sourceLine" id="cb3-13" data-line-number="13"><span class="co">#&gt;    Variable Importance</span></a>
<a class="sourceLine" id="cb3-14" data-line-number="14"><span class="co">#&gt;    &lt;chr&gt;         &lt;dbl&gt;</span></a>
<a class="sourceLine" id="cb3-15" data-line-number="15"><span class="co">#&gt;  1 x.4         76.8   </span></a>
<a class="sourceLine" id="cb3-16" data-line-number="16"><span class="co">#&gt;  2 x.2         62.9   </span></a>
<a class="sourceLine" id="cb3-17" data-line-number="17"><span class="co">#&gt;  3 x.1         53.8   </span></a>
<a class="sourceLine" id="cb3-18" data-line-number="18"><span class="co">#&gt;  4 x.5         37.6   </span></a>
<a class="sourceLine" id="cb3-19" data-line-number="19"><span class="co">#&gt;  5 x.3         22.9   </span></a>
<a class="sourceLine" id="cb3-20" data-line-number="20"><span class="co">#&gt;  6 x.9          1.18  </span></a>
<a class="sourceLine" id="cb3-21" data-line-number="21"><span class="co">#&gt;  7 x.8          1.02  </span></a>
<a class="sourceLine" id="cb3-22" data-line-number="22"><span class="co">#&gt;  8 x.7         -0.0363</span></a>
<a class="sourceLine" id="cb3-23" data-line-number="23"><span class="co">#&gt;  9 x.10        -0.457 </span></a>
<a class="sourceLine" id="cb3-24" data-line-number="24"><span class="co">#&gt; 10 x.6         -1.65</span></a>
<a class="sourceLine" id="cb3-25" data-line-number="25"></a>
<a class="sourceLine" id="cb3-26" data-line-number="26"><span class="co"># Use `vip()` to construct ggplot2-based variable importance plots</span></a>
<a class="sourceLine" id="cb3-27" data-line-number="27">p1 &lt;-<span class="st"> </span><span class="kw"><a href="reference/vip.html">vip</a></span>(rf, <span class="dt">type =</span> <span class="dv">1</span>) <span class="op">+</span><span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/labs">ggtitle</a></span>(<span class="st">"RF: accuracy"</span>)</a>
<a class="sourceLine" id="cb3-28" data-line-number="28">p2 &lt;-<span class="st"> </span><span class="kw"><a href="reference/vip.html">vip</a></span>(rf, <span class="dt">type =</span> <span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/labs">ggtitle</a></span>(<span class="st">"RF: impurity"</span>)</a>
<a class="sourceLine" id="cb3-29" data-line-number="29">p3 &lt;-<span class="st"> </span><span class="kw"><a href="reference/vip.html">vip</a></span>(rf, <span class="dt">method =</span> <span class="st">"ice"</span>) <span class="op">+</span><span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/labs">ggtitle</a></span>(<span class="st">"ICE"</span>)</a>
<a class="sourceLine" id="cb3-30" data-line-number="30"><span class="co">#&gt; Warning: Setting `method = "ice"` is experimental, use at your own risk!</span></a>
<a class="sourceLine" id="cb3-31" data-line-number="31"><span class="kw"><a href="reference/grid.arrange.html">grid.arrange</a></span>(p1, p2, p3, <span class="dt">ncol =</span> <span class="dv">3</span>)</a></code></pre></div>
<p><img src="reference/figures/README-example-rf-1.png" width="700" style="display: block; margin: auto;"></p>
</div>
<div id="references" class="section level2">
<h2 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h2>
<p>Breiman, L. “Random Forests”. <em>Machine Learning</em>. <strong>45</strong>(1): 5-32, 2001. URL <a href="https://doi.org/10.1023/A:1010933404324" class="uri">https://doi.org/10.1023/A:1010933404324</a>.</p>
<p>Friedman, J. H. “Greedy function approximation: A gradient boosting machine”. <em>The Annals of Statistics</em>, <strong>29</strong>: 1189–1232, 2001. URL <a href="https://doi.org/10.1214/aos/1013203451" class="uri">https://doi.org/10.1214/aos/1013203451</a></p>
<p>Greenwell, B. M., Boehmke, B. C., and McCarthy, A. J. “A Simple and Effective Model-Based Variable Importance Measure”. arXiv preprint, 2018. URL <a href="https://arxiv.org/abs/1805.04755" class="uri">https://arxiv.org/abs/1805.04755</a>.</p>
<p>Goldstein, A., Kapelner, A., Bleich, J., and Pitkin, E. (2015) “Peeking inside the black box: Visualizing statistical learning with plots of individual conditional expectation”. <em>Journal of Computational and Graphical Statistics</em>, <strong>24</strong>*(1): 44-65, 2015. URL <a href="https://doi.org/10.1080/10618600.2014.907095" class="uri">https://doi.org/10.1080/10618600.2014.907095</a>.</p>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <div class="links">
<h2>Links</h2>
<ul class="list-unstyled">
<li>Download from CRAN at <br><a href="https://cloud.r-project.org/package=vip">https://​cloud.r-project.org/​package=vip</a>
</li>
<li>Browse source code at <br><a href="https://github.com/koalaverse/vip">https://​github.com/​koalaverse/​vip</a>
</li>
<li>Report a bug at <br><a href="https://github.com/koalaverse/vip/issues">https://​github.com/​koalaverse/​vip/​issues</a>
</li>
</ul>
</div>
<div class="license">
<h2>License</h2>
<ul class="list-unstyled">
<li>GPL (&gt;= 2)</li>
</ul>
</div>
<div class="developers">
<h2>Developers</h2>
<ul class="list-unstyled">
<li>Brandon Greenwell <br><small class="roles"> Author, maintainer </small> <a href="https://orcid.org/0000-0002-8120-0084" target="orcid.widget"><img src="https://members.orcid.org/sites/default/files/vector_iD_icon.svg" class="orcid" height="16"></a> </li>
<li>Brad Boehmke <br><small class="roles"> Author </small> <a href="https://orcid.org/0000-0002-3611-8516" target="orcid.widget"><img src="https://members.orcid.org/sites/default/files/vector_iD_icon.svg" class="orcid" height="16"></a> </li>
</ul>
</div>

      <div class="dev-status">
<h2>Dev status</h2>
<ul class="list-unstyled">
<li><a href="https://cran.r-project.org/package=vip"><img src="http://www.r-pkg.org/badges/version/vip" alt="CRAN_Status_Badge"></a></li>
<li><a href="https://travis-ci.org/koalaverse/vip"><img src="https://travis-ci.org/koalaverse/vip.svg?branch=master" alt="Travis-CI Build Status"></a></li>
<li><a href="https://ci.appveyor.com/project/koalaverse/vip"><img src="https://ci.appveyor.com/api/projects/status/github/koalaverse/vip?branch=master&amp;svg=true" alt="AppVeyor Build Status"></a></li>
<li><a href="https://www.tidyverse.org/lifecycle/#stable"><img src="https://img.shields.io/badge/lifecycle-maturing-brightgreen.svg" alt="lifecycle"></a></li>
</ul>
</div>
</div>

</div>


      <footer><div class="copyright">
  <p>Developed by Brandon Greenwell, Brad Boehmke.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  

  </body>
</html>
