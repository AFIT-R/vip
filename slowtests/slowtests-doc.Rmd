---
title: "Tests for the vip package"
author: "Brandon M. Greenwell"
date: "5/7/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  cache = TRUE,
  echo = TRUE
)
```

```{r packages-and-data}
# Load required packages
library(vip)

# Function to bin a numeric vector
bin <- function(x, num_bins) {
  quantiles <- quantile(x, probs = seq(from = 0, to = 1, length = num_bins + 1))
  bins <- cut(x, breaks = quantiles, label = FALSE, include.lowest = TRUE)
  as.factor(paste0("class", bins))
}

# Simulate Friedman's data
set.seed(101)  # for reproducibility
friedman1 <- friedman2 <- friedman3 <-
  as.data.frame(mlbench::mlbench.friedman1(1000, sd = 0.1))
friedman2$y <- bin(friedman1$y, num_bins = 2)
friedman3$y <- bin(friedman1$y, num_bins = 3)
```


### Package: xyz

#### Binary classification

```{r xyx-binary}
# Fit model
fit <- NULL

# Compute variable importance
res <- NULL

# Variable importance plot(s)
```

#### Multiclass classification

```{r xyx-multiclass}
# Fit model
fit <- NULL

# Compute variable importance
res <- NULL

# Variable importance plot(s)
```

#### Regression

```{r xyx-regression}
# Fit model
fit <- NULL

# Compute variable importance
res <- NULL

# Variable importance plot(s)
```


## Model-based 

Some machine learning algorithms have their own way of quantifying variable Importance. We describe some of these in the subsection that follow. The issue with model-specific VI scores is that they are not necessarily comparable across different types of models. For example, directly computing the impurity-based VI scores from tree-based models to the $t$-statistic from linear models.


### Package: C50

#### Binary classification

```{r C50-binary}
# Fit model
fit <- C50::C5.0(y ~ ., data = friedman2)

# Compute variable importance
res1 <- vi_model(fit, type = "usage")
res2 <- vi_model(fit, type = "splits")

# Variable importance plot(s)
grid.arrange(
  vip(res1, num_features = 16), 
  vip(res2, num_features = 16), 
  nrow = 1
)
```

#### Multiclass classification

```{r C50-multiclass}
print("Does not support multiclass classification.")
```

#### Regression

```{r C50-regression}
print("Does not support regression.")
```

### Package: caret

#### Binary classification

```{r caret-binary}
# Fit model
set.seed(101)  # for reproducibility
fit <- caret::train(
  y ~ ., data = friedman2,
  method = "ranger",
  importance = "impurity",
  tuneLength = 1
)

# Compute variable importance
res1 <- vi_model(fit)
res2 <- vi_model(fit$finalModel)

# Variable importance plot(s)
grid.arrange(
  vip(res1, num_features = 16), 
  vip(res2, num_features = 16), 
  nrow = 1
)
```

#### Multiclass classification

```{r caret-multi}
# Fit model
set.seed(101)  # for reproducibility
fit <- caret::train(
  y ~ ., data = friedman3,
  method = "ranger",
  importance = "impurity",
  tuneLength = 1
)

# Compute variable importance
res1 <- vi_model(fit)
res2 <- vi_model(fit$finalModel)

# Variable importance plot(s)
grid.arrange(
  vip(res1, num_features = 16), 
  vip(res2, num_features = 16), 
  nrow = 1
)
```

#### Regression

```{r caret-regression}
# Fit model
set.seed(101)  # for reproducibility
fit <- caret::train(
  y ~ ., data = friedman1,
  method = "ranger",
  importance = "impurity",
  tuneLength = 1
)

# Compute variable importance
res1 <- vi_model(fit)
res2 <- vi_model(fit$finalModel)

# Variable importance plot(s)
grid.arrange(
  vip(res1, num_features = 16), 
  vip(res2, num_features = 16), 
  nrow = 1
)
```


### Package: Cubist

#### Binary classification

```{r Cubist-binary}
print("Does not support binary classification.")
```

#### Multiclass classification

```{r Cubist-multiclass}
print("Does not support multiclass classification.")
```

#### Regression

```{r Cubist-regression}
# Fit model
fit <- Cubist::cubist(
  x = subset(friedman1, select = -y),
  y = friedman1$y,
  committees = 10
)

# Compute variable importance
res1 <- vi_model(fit)
res2 <- vi_model(fit, weights = c(0.1, 0.9))

# Variable importance plot(s)
grid.arrange(
  vip(res1, num_features = 16), 
  vip(res2, num_features = 16), 
  nrow = 1
)
```


### Package: earth

#### Binary classification

```{r earth-binary}
# Fit model
fit <- earth::earth(y ~ ., data = friedman2, degree = 2,
                     glm = list(family = binomial))

# Compute variable importance
res1 <- vi_model(fit)
res2 <- vi_model(fit, type = "rss")
res3 <- vi_model(fit, type = "gcv")

# Variable importance plot(s)
grid.arrange(
  vip(res1, num_features = 16),
  vip(res2, num_features = 16),
  vip(res3, num_features = 16),
  nrow = 1
)
```

#### Multiclass classification

```{r earth-multiclass}
# # Fit model
# fit <- earth::earth(y ~ ., data = friedman3, degree = 2,
#                      glm = list(family = binomial))
# 
# # Compute variable importance
# res1 <- vi_model(fit)
# res2 <- vi_model(fit, type = "rss")
# res3 <- vi_model(fit, type = "gcv")
# 
# # Variable importance plot(s)
# grid.arrange(
#   vip(res1, num_features = 16),
#   vip(res2, num_features = 16),
#   vip(res3, num_features = 16),
#   nrow = 1
# )
```

#### Regression

```{r earth-regression}
# Fit model
fit <- earth::earth(y ~ ., data = friedman1, degree = 2)

# Compute variable importance
res1 <- vi_model(fit)
res2 <- vi_model(fit, type = "rss")
res3 <- vi_model(fit, type = "gcv")

# Variable importance plot(s)
grid.arrange(
  vip(res1, num_features = 16),
  vip(res2, num_features = 16),
  vip(res3, num_features = 16),
  nrow = 1
)
```


### Package: gbm

#### Binary classification

```{r gbm-binary}
friedman2_01 <- friedman2
friedman2_01$y <- ifelse(friedman2_01$y == "class1", 1, 0)

# Fit model
set.seed(101)  # for reproducibility
fit <- gbm::gbm(
  y ~ .,
  data = friedman2_01,
  distribution = "bernoulli",
  n.trees = 1000,
  interaction.depth = 5,
  shrinkage = 0.1,
  bag.fraction = 1,
  cv.folds = 5
)
best_iter <- gbm::gbm.perf(fit, plot.it = FALSE, method = "cv")

# Compute variable importance
set.seed(102)  # for reproducibility
res1 <- vi_model(fit, n.trees = best_iter)
res2 <- vi_model(fit, type = "permutation", n.trees = best_iter)

# Variable importance plot(s)
grid.arrange(
  vip(res1, num_features = 16),
  vip(res2, num_features = 16),
  nrow = 1
)
```

#### Multiclass classification

```{r gbm-multiclass}
# Fit model
set.seed(101)  # for reproducibility
fit <- gbm::gbm(
  y ~ .,
  data = friedman3,
  distribution = "multinomial",
  n.trees = 1000,
  interaction.depth = 5,
  shrinkage = 0.1,
  bag.fraction = 1,
  cv.folds = 5
)
best_iter <- gbm::gbm.perf(fit, plot.it = FALSE, method = "cv")

# Compute variable importance
set.seed(102)  # for reproducibility
res <- vi_model(fit, n.trees = best_iter)
# res <- vi_model(fit, type = "permutation", n.trees = best_iter)  # not supported

# Variable importance plot(s)
vip(res, num_features = 16)
```

#### Regression

```{r gbm-regression}
# Fit model
set.seed(101)  # for reproducibility
fit <- gbm::gbm(
  y ~ .,
  data = friedman1,
  distribution = "gaussian",
  n.trees = 1000,
  interaction.depth = 5,
  shrinkage = 0.1,
  bag.fraction = 1,
  cv.folds = 5
)
best_iter <- gbm::gbm.perf(fit, plot.it = FALSE, method = "cv")

# Compute variable importance
set.seed(102)  # for reproducibility
res1 <- vi_model(fit, n.trees = best_iter)
res2 <- vi_model(fit, type = "permutation", n.trees = best_iter)

# Variable importance plot(s)
grid.arrange(
  vip(res1, num_features = 16),
  vip(res2, num_features = 16),
  nrow = 1
)
```


### Package: glmnet

#### Binary classification

```{r glmnet-binary}
# Fit model
fit1 <- glmnet::glmnet(
  x = model.matrix(~ . - y - 1, data = friedman2), 
  y = friedman2$y, 
  family = "binomial",
  nlambda = 100
)

# Fit model using 5-fold CV
fit2 <- glmnet::cv.glmnet(
  x = model.matrix(~ . - y - 1, data = friedman2),
  y = friedman2$y,
  family = "binomial",
  nfolds = 5
)

# Compute variable importance
res1 <- vi_model(fit1)
res2 <- vi_model(fit2)

# Variable importance plot(s)
grid.arrange(
  vip(res1, num_features = 16),
  vip(res2, num_features = 16),
  nrow = 1
)
```

#### Multiclass classification

```{r glmnet-multiclass}
# Fit model
fit1 <- glmnet::glmnet(
  x = model.matrix(~ . - y - 1, data = friedman3), 
  y = friedman3$y, 
  family = "multinomial",
  nlambda = 100
)

# Fit model using 5-fold CV
fit2 <- glmnet::cv.glmnet(
  x = model.matrix(~ . - y - 1, data = friedman3),
  y = friedman3$y,
  family = "multinomial",
  nfolds = 5
)

# Compute variable importance
res1 <- vi_model(fit1)
res2 <- vi_model(fit2)

# Variable importance plot(s)
grid.arrange(
  vip(res1, num_features = 16),
  vip(res2, num_features = 16),
  nrow = 1
)
```

#### Regression

```{r glmnet-regression}
# Fit model
fit1 <- glmnet::glmnet(
  x = model.matrix(~ . - y - 1, data = friedman1), 
  y = friedman1$y, 
  nlambda = 100
)

# Fit model using 5-fold CV
fit2 <- glmnet::cv.glmnet(
  x = model.matrix(~ . - y - 1, data = friedman1),
  y = friedman1$y,
  nfolds = 5
)

# Compute variable importance
res1 <- vi_model(fit1)
res2 <- vi_model(fit2)

# Variable importance plot(s)
grid.arrange(
  vip(res1, num_features = 16),
  vip(res2, num_features = 16),
  nrow = 1
)
```


### Package: h2o

### Package: neuralnet

```{r neuralnet}
# Fit model
fit <- neuralnet::neuralnet(y ~ ., data = data.matrix(friedman1))

# Compute variable importance
res1 <- vi_model(fit)
res2 <- vi_model(fit, type = "garson")

# Variable importance plot(s)
grid.arrange(
  vip(res1, num_features = 16),
  vip(res2, num_features = 16),
  nrow = 1
)
```


### Package: nnet

```{r nnet}
# Fit model
fit <- nnet::nnet(
  y ~ .,
  data = friedman1,
  size = 10,
  linout = TRUE,
  decay = 0.1,
  maxit = 1000,
  trace = FALSE
)

# Compute variable importance
res1 <- vi_model(fit)
res2 <- vi_model(fit, type = "garson")

# Variable importance plot(s)
grid.arrange(
  vip(res1, num_features = 16),
  vip(res2, num_features = 16),
  nrow = 1
)
```


### Package: party

```{r party}
# Fit model
set.seed(101)  # for reproducibility
fit <- party::cforest(y ~ ., data = friedman2)

# Compute variable importance
res1 <- vi_model(fit)
res2 <- vi_model(fit, type = "auc", nperm = 10)

# Variable importance plot(s)
set.seed(102)  # for reproducibility
grid.arrange(
  vip(res1, num_features = 16),
  vip(res2, num_features = 16),
  nrow = 1
)
```


### Package: partykit
### Package: randomForest

```{r randomForest}
# Fit model
set.seed(101)  # for reproducibility
fit1 <- randomForest::randomForest(y ~ ., data = friedman1)
fit2 <- randomForest::randomForest(y ~ ., data = friedman1, importance = TRUE)

# Compute variable importance
res1 <- vi_model(fit1)
res2 <- vi_model(fit2)

# Variable importance plot(s)
grid.arrange(
  vip(res1, num_features = 16),
  vip(res2, num_features = 16),
  nrow = 1
)
```


### Package: ranger

```{r ranger}
# Fit model
set.seed(101)  # for reproducibility
fit1 <- ranger::ranger(y ~ ., data = friedman1, importance = "impurity")
fit2 <- ranger::ranger(y ~ ., data = friedman1, importance = "impurity_corrected")
fit3 <- ranger::ranger(y ~ ., data = friedman1, importance = "permutation")

# Compute variable importance
res1 <- vi_model(fit1)
res2 <- vi_model(fit2)
res3 <- vi_model(fit3)

# Variable importance plot(s)
grid.arrange(
  vip(res1, num_features = 16),
  vip(res2, num_features = 16),
  vip(res3, num_features = 16),
  nrow = 1
)
```


### Package: rpart
### Package: RSNNS

```{r rsnns}
# Fit model
fit <- RSNNS::mlp(
  x = model.matrix(~ . - y - 1, data = friedman1), 
  y = friedman1$y, 
  size = 5,
  linOut = TRUE
)

# Compute variable importance
res1 <- vi_model(fit)
res2 <- vi_model(fit, type = "garson")

# Variable importance plot(s)
grid.arrange(
  vip(res1, num_features = 16),
  vip(res2, num_features = 16),
  nrow = 1
)
```


### Package: sparklyr
### Package: stats

```{r lm}
# Fit model
fit1 <- lm(y ~ ., data = friedman1)
fit2 <- glm(y ~ ., data = friedman1)

# Compute variable importance
res1 <- vi_model(fit1)
res2 <- vi_model(fit2)

# Variable importance plot(s)
grid.arrange(
  vip(res1, num_features = 16), 
  vip(res2, num_features = 16), 
  nrow = 1
)
```


### Package: xgboost

```{r xgboost}
# Fit model
set.seed(101)  # for reproducibility
fit <- xgboost::xgboost(
  data = model.matrix(~ . - y - 1, data = friedman1), 
  label = friedman1$y,
  nrounds = 50,
  params = list(eta = 0.1),
  verbose = 0,
  save_period = 0
)

# Compute variable importance
res1 <- vi_model(fit)
res2 <- vi_model(fit, type = "cover")
res3 <- vi_model(fit, type = "frequency")

# Variable importance plot(s)
grid.arrange(
  vip(res1, num_features = 16),
  vip(res2, num_features = 16),
  vip(res3, num_features = 16),
  nrow = 1
)
```
