---
output: github_document
---

```{r setup, echo = FALSE}
knitr::opts_chunk$set(
  cache = TRUE,
  collapse = TRUE,
  comment = "#>",
  fig.align = "center",
  fig.path = "man/figures/README-"
)
```

# vip: Variable Importance Plots <img src="man/figures/logo-vip.png" align="right" width="130" height="150" />

[![CRAN_Status_Badge](http://www.r-pkg.org/badges/version/vip)](https://cran.r-project.org/package=vip)
[![Travis-CI Build Status](https://travis-ci.org/koalaverse/vip.svg?branch=master)](https://travis-ci.org/koalaverse/vip)
[![AppVeyor Build Status](https://ci.appveyor.com/api/projects/status/github/koalaverse/vip?branch=master&svg=true)](https://ci.appveyor.com/project/koalaverse/vip)
[![lifecycle](https://img.shields.io/badge/lifecycle-maturing-brightgreen.svg)](https://www.tidyverse.org/lifecycle/#stable)


## Overview

`vip` is an R package for constructing **v**ariable **i**mportance **p**lots (VIPs). VIPs are part of a larger framework referred to as *interpretable machine learning* (IML), which includes (but not limited to): partial dependence plots (PDPs) and individual conditional expectation (ICE) curves. While PDPs and ICE curves (available in the R package [pdp](https://cran.r-project.org/package=pdp)) help visualize feature effects, VIPs help visualize feature impact (either locally or globally). An in-progress, but comprehensive, overview of IML can be found here: https://github.com/christophM/interpretable-ml-book.


## Installation

```{r, eval = FALSE}
# The easiest way to get vip is to install it from CRAN:
install.packages("vip")

# ALternatively, you can install the development version from GitHub:
if (!requireNamespace("devtools")) {
  install.packages("devtools")
}
devtools::install_github("koalaverse/vip")
```


## Example usage

For illustration, we'll use one of the regression problems described in Friedman (1991) and Breiman (1996). These data are available in the [mlbench](https://CRAN.R-project.org/package=mlbench) package. The inputs consist of 10 independent variables uniformly distributed on the interval $\left[0, 1\right]$; however, only 5 out of these 10 are actually used in the true model. Outputs are created according to the formula described in `?mlbench::mlbench.friedman1`. The code chunk below simulates 500 observations from the model default standard deviation.
```{r simulate-data}
# Simulate training data
set.seed(101)  # for reproducibility
trn <- as.data.frame(mlbench::mlbench.friedman1(500))  # ?mlbench.friedman1
```
Next, we fit a random forest to the simulated data and construct variable importance plots using three different approaches: 1) the impurity-based random forest method (also available for other tree-based algorithms); the ICE-based method described in ; and 3) a permutation-based approach. Method 1) is specific to random forests (and other tree-based methods), whereas methods 2)--3) are model-agnostic and can be applied to **any supervised learning algorithm**. In this example, all three methods do a fantastic job at highlighting the five variables used in the true model.
```{r example-rf}
# Load required packages
library(ggplot2)  # for ggtitle() function
library(ranger)  # for efficient random forest algorithm
library(vip)  # for visualizing feature impact

# Fit a random forest
set.seed(102)  # for reproducibility
rfo <- ranger(
  formula = y ~ ., 
  data = trn, 
  importance = "impurity"  # include RF-based variable importance measure
)

# Use `vi()` to return a tibble of variable importance (VI) scores
vi(rfo)  # default is to construct model-based VI scores (if available)

# Use `vip()` to construct ggplot2-based VIPs
p1 <- vip(rfo)
# The following two can be run in parallel by setting `parallel = TRUE` with an
# appropriate parallel backend loaded (see the vignette for details)
p2 <- vip(rfo, method = "ice")  # warning: can be computationally expensive!
set.seed(103)  # for reproducibility
p3 <- vip(rfo, method = "permute", obs = trn$y)
grid.arrange(p1, p2, p3, ncol = 3)
```
